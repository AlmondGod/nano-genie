# Training
batch_size: 256
n_updates: 20000
learning_rate: 0.0001
log_interval: 250
dataset: ZELDA
context_length: 4
frame_size: 128

# Model (must match tokenizer)
patch_size: 8
embed_dim: 128
num_heads: 8
hidden_dim: 256
num_blocks: 4
latent_dim: 6
num_bins: 4
n_actions: 8
use_actions: false

# Paths
video_tokenizer_path: null
lam_path: null

# Performance
amp: true
tf32: true
compile: true

# W&B
use_wandb: true
wandb_project: nano-genie
wandb_run_name: null

# Save
save: true
filename: null 