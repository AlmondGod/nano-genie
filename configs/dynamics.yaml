# Training
batch_size: 256
n_updates: 100000
learning_rate: 0.0001
log_interval: 2500

# Model (must match tokenizer)
embed_dim: 128
num_heads: 8
hidden_dim: 256
num_blocks: 4

use_actions: true

# Paths
video_tokenizer_path: null
latent_actions_path: null

# Save
save: true
filename: null 