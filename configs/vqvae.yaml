# Training
batch_size: 256
n_updates: 20000
learning_rate: 0.0004
log_interval: 250
dataset: ZELDA
context_length: 4
frame_size: 128

# Model
patch_size: 8
embed_dim: 128
num_heads: 8
hidden_dim: 256
num_blocks: 4
latent_dim: 6
num_bins: 4

# Save/IO
save: true
filename: null
checkpoint: null
start_iteration: 0

# Performance
amp: true
tf32: true
compile: true

# W&B
use_wandb: true
wandb_project: nano-genie
wandb_run_name: null

# Debug
debug_stats: true 